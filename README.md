## Table of Content

* [Presenters](#presenters)
* [Abstract](#abstract)
* [Link to Slides](#link-to-slides)
* [Notebooks](#notebooks)
* [References](#references)


## Presenters


## Abstract

Since the celebrated book by Rasmussen and Williams, there have been a considerable amount of novel contributions that are allowing the applicability of Gaussian processes (GPs) to problems at an unprecedented scale and to new areas where uncertainty quantification is of fundamental importance. 
This tutorial will expose attendees to recent advances in GP research; describe the current challenges in modeling and inference with GPs; their relationship to neural networks and deep neural networks and stimulate the debate about the role of GP models in solving complex machine-learning tasks. 

## Link to Slides

* [Introduction](slides/introduction.pdf)
* [Definition of Gaussian Processes](slides/gaussian_processes.pdf)
* [Model Approximations](slides/model_approximations.pdf)
* [Inference](slides/inference.pdf)
* [Challenges](slides/challenges.pdf)
* [Theory and Code](slides/theory_code.pdf)




## Notebooks

[Notebook Sampling from GP prior](notebooks/gp-priors.ipynb)

[Notebook on GP Regression](notebooks/gp-inference.ipynb)


## References

<link rel="import" href="references/references.html">
### Unsupervised learning with Deep Gaussian Processes
<ul>



<li><a name="Domingues18"></a>

R.&nbsp;Domingues, P.&nbsp;Michiardi, J.&nbsp;Zouaoui, and M.&nbsp;Filippone.
 Deep Gaussian process autoencoders for novelty detection.
 <em>Machine Learning</em>, 107(8-10):1363--1383, 2018.
[&nbsp;<a href="http://dx.doi.org/10.1007/s10994-018-5723-3">DOI</a>&nbsp;]

</li>

<li><a name="Dai15"></a>

Z.&nbsp;Dai, A.&nbsp;Damianou, J.&nbsp;Gonz&aacute;lez, and N.&nbsp;Lawrence.
 Variational Auto-encoded Deep Gaussian Processes, Feb. 2016.
[&nbsp;<a href="http://arxiv.org/abs/1511.06455">arXiv</a>&nbsp;]

</li></ul>
